{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoawwazTahir/Wardrobe_proj/blob/main/qwen2_vl_2b_api_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BNbKOc1jP7Dr"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "#!pip install flask pyngrok transformers torch Pillow requests qwen_vl_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "f27d0fd951a14570af56f02d046e65c1",
            "b9557a6e12554ae2807308a2be7f17bb",
            "6c161aa97a454830b6523171687a17e3",
            "e7079877dadd4e8eace46e41378b9a8c",
            "fdedd23dd39f407c9a93418715ba9ea9",
            "e22eb74378ba4220a7403e6a79ca1c0b",
            "bf91b6e522e1450dadaa59f72e02cab7",
            "19916bc5456149cc85ee634674f423b8",
            "49fef6bce6224c9fa008290127fcf615",
            "6032599f95eb447a85ba069fa6c8be46",
            "b106c18e750941c9846dac873380ff26"
          ]
        },
        "id": "oPV6m6nSO4vM",
        "outputId": "ab6649ab-6569-4c3f-f1c4-6be8cbb86336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f27d0fd951a14570af56f02d046e65c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "Processor loaded successfully with image resizing (200704 - 1003520 pixels).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import gc\n",
        "from PIL import Image\n",
        "from flask import Flask, request, jsonify\n",
        "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info  # Assuming process_vision_info is available\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set up the Ngrok authentication token\n",
        "ngrok_auth_token = \"2p0tNdsPkUnSJELTDbhUEuYaC0I_6GRKZSEK5Y4xJWj3RApdK\"  # Replace with your actual Ngrok token\n",
        "ngrok.set_auth_token(ngrok_auth_token)  # Set Ngrok auth token\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the model and processor\n",
        "def load_model_and_processor(min_pixels=256 * 28 * 28, max_pixels=1280 * 28 * 28):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    try:\n",
        "        model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "            \"Qwen/Qwen2-VL-2B-Instruct\",\n",
        "            torch_dtype=torch.bfloat16 if device.type == \"cuda\" else torch.float32,\n",
        "            device_map=\"auto\",  # You can remove this line if it conflicts with single GPU usage\n",
        "        )\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "    try:\n",
        "        processor = AutoProcessor.from_pretrained(\n",
        "            \"Qwen/Qwen2-VL-2B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels\n",
        "        )\n",
        "        print(f\"Processor loaded successfully with image resizing ({min_pixels} - {max_pixels} pixels).\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading processor: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "    model.to(device)  # Move the model to the specified device\n",
        "    model.eval()\n",
        "    return model, processor, device\n",
        "\n",
        "# Load model and processor\n",
        "model, processor, device = load_model_and_processor()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_generate_method(model):\n",
        "    return model.generate\n",
        "\n",
        "def process_image_and_generate_caption(image_url: str):\n",
        "    try:\n",
        "        # Fetch image from URL\n",
        "        if image_url.startswith('http'):\n",
        "            response = requests.get(image_url)\n",
        "\n",
        "            # Check if the response is an image\n",
        "            if 'image' not in response.headers.get('Content-Type', ''):\n",
        "                raise ValueError(f\"URL does not return a valid image: {image_url}\")\n",
        "\n",
        "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "            print(f\"Image fetched from URL: {image_url}\")\n",
        "        else:\n",
        "            img = Image.open(image_url).convert(\"RGB\")\n",
        "            print(f\"Image loaded from file: {image_url}\")\n",
        "\n",
        "        # Resize image\n",
        "        img = img.resize((1024, 1024))\n",
        "        print(f\"Image size after resizing: {img.size}\")\n",
        "\n",
        "        # Prepare image data using process_vision_info (to match the original code's intent)\n",
        "        messages = [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img},\n",
        "                {\"type\": \"text\", \"text\": \"Describe this image.\"}\n",
        "            ]\n",
        "        }]\n",
        "\n",
        "        text = processor.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        # Process vision info (this should match how your original code processed images)\n",
        "        image_inputs, video_inputs = process_vision_info(messages)\n",
        "\n",
        "        # Prepare the input for the model using the processor\n",
        "        inputs = processor(\n",
        "            text=[text],\n",
        "            images=image_inputs,\n",
        "            videos=video_inputs,\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "        # Check the structure of the inputs\n",
        "        print(f\"Inputs from processor: {inputs}\")\n",
        "\n",
        "        # Ensure inputs are valid\n",
        "        if 'input_ids' not in inputs or 'attention_mask' not in inputs or 'pixel_values' not in inputs:\n",
        "            raise ValueError(\"Invalid inputs returned by the processor.\")\n",
        "\n",
        "        # Generate caption\n",
        "        generate = get_generate_method(model)\n",
        "        with torch.no_grad():\n",
        "            generated_ids = generate(**inputs, max_new_tokens=128)\n",
        "            generated_ids_trimmed = [\n",
        "                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "            ]\n",
        "            output_text = processor.batch_decode(\n",
        "                generated_ids_trimmed,\n",
        "                skip_special_tokens=True,\n",
        "                clean_up_tokenization_spaces=False\n",
        "            )\n",
        "\n",
        "        # Return the caption\n",
        "        return output_text[0], img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "        return None, None\n",
        "\n",
        "@app.route('/generate_caption', methods=['POST'])\n",
        "def generate_caption():\n",
        "    data = request.get_json()\n",
        "\n",
        "    # Ensure image URL or file is provided\n",
        "    if \"image_url\" not in data:\n",
        "        return jsonify({\"error\": \"No image URL provided\"}), 400\n",
        "\n",
        "    image_url = data[\"image_url\"]\n",
        "    caption, image = process_image_and_generate_caption(image_url)\n",
        "\n",
        "    if caption:\n",
        "        return jsonify({\"caption\": caption, \"status\": \"success\"})\n",
        "    else:\n",
        "        return jsonify({\"error\": \"Failed to generate caption\", \"status\": \"failed\"}), 500\n",
        "\n"
      ],
      "metadata": {
        "id": "Zhhnr7a7sNtL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Flask app with Ngrok\n",
        "if __name__ == \"__main__\":\n",
        "    # Start Ngrok tunnel for Flask app on port 5000\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"Flask app is publicly available at {public_url}\")\n",
        "\n",
        "    # Run the Flask app\n",
        "    app.run(debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfIgFfrSkSWd",
        "outputId": "fede2919-df52-4497-992c-6fd88e710b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flask app is publicly available at NgrokTunnel: \"https://5be6-35-240-161-166.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image fetched from URL: https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Male_cheetah_facing_left_in_South_Africa.jpg/220px-Male_cheetah_facing_left_in_South_Africa.jpg\n",
            "Image size after resizing: (1024, 1024)\n",
            "Inputs from processor: {'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-0.6244, -0.6536, -0.6974,  ..., -1.4376, -1.2811, -1.0536],\n",
            "        [ 0.2953,  0.6749,  0.9230,  ..., -1.1816, -1.2811, -1.3807],\n",
            "        [-0.3470, -0.3908, -0.4784,  ..., -1.3380, -1.3522, -1.3380],\n",
            "        ...,\n",
            "        [ 0.7917,  0.8209,  0.8355,  ...,  0.0555,  0.0413,  0.0698],\n",
            "        [ 0.9084,  0.8647,  0.8063,  ..., -0.1151, -0.1151, -0.1293],\n",
            "        [ 0.2077,  0.1639,  0.1493,  ...,  0.1124,  0.1266,  0.1266]],\n",
            "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 70, 70]], device='cuda:0')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2024 09:58:56] \"POST /generate_caption HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOTuNI1iwm71zGd0Q3i9Xwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f27d0fd951a14570af56f02d046e65c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9557a6e12554ae2807308a2be7f17bb",
              "IPY_MODEL_6c161aa97a454830b6523171687a17e3",
              "IPY_MODEL_e7079877dadd4e8eace46e41378b9a8c"
            ],
            "layout": "IPY_MODEL_fdedd23dd39f407c9a93418715ba9ea9"
          }
        },
        "b9557a6e12554ae2807308a2be7f17bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22eb74378ba4220a7403e6a79ca1c0b",
            "placeholder": "​",
            "style": "IPY_MODEL_bf91b6e522e1450dadaa59f72e02cab7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6c161aa97a454830b6523171687a17e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19916bc5456149cc85ee634674f423b8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49fef6bce6224c9fa008290127fcf615",
            "value": 2
          }
        },
        "e7079877dadd4e8eace46e41378b9a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6032599f95eb447a85ba069fa6c8be46",
            "placeholder": "​",
            "style": "IPY_MODEL_b106c18e750941c9846dac873380ff26",
            "value": " 2/2 [00:03&lt;00:00,  1.37s/it]"
          }
        },
        "fdedd23dd39f407c9a93418715ba9ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e22eb74378ba4220a7403e6a79ca1c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf91b6e522e1450dadaa59f72e02cab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19916bc5456149cc85ee634674f423b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49fef6bce6224c9fa008290127fcf615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6032599f95eb447a85ba069fa6c8be46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b106c18e750941c9846dac873380ff26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}