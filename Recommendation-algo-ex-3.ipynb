{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":329006,"sourceType":"datasetVersion","datasetId":139630},{"sourceId":9701193,"sourceType":"datasetVersion","datasetId":5932428},{"sourceId":9701704,"sourceType":"datasetVersion","datasetId":5932825},{"sourceId":9701741,"sourceType":"datasetVersion","datasetId":5932852}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence_transformers einops\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport random\nimport numpy as np\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\n\n# Load CSV file\ndf = pd.read_csv(\"/kaggle/input/demo-csv-2/Demo_captions_2.csv\")\n\n# Define the base directory for the images\nimage_dir = \"/kaggle/input/demo-pics-2/Demo closet\"\n\n# Update the image file paths\ndf['Image File Path'] = df['Image File Name'].apply(lambda x: os.path.join(image_dir, x))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the model\nmodel_name = \"nomic-ai/nomic-embed-text-v1\"\nmodel = SentenceTransformer(model_name, trust_remote_code=True, device='cpu')\n\n# Function to generate embedding for a text\ndef generate_embedding(text):\n    embedding = model.encode([text])[0]  # Generate embedding\n    return embedding\n\n# Combine relevant columns to form item description for embeddings\ndf['description'] = df[['Outfit Piece', 'Pattern', 'Color', 'Material', 'Season', 'Weather', 'Dress code']].apply(\n    lambda row: ' '.join(row.values.astype(str)), axis=1\n)\n\n# Generate embeddings for each clothing item\ndf['embedding'] = df['description'].apply(lambda x: generate_embedding(x))\n\n# Set Outfit Context based on 'Dress code'\ndf['Outfit Context'] = df['Dress code']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Global variables for adjustable weights\nembedding_weight = 1  # Adjustable weight for embedding similarity\ncontext_weight = 10   # Adjustable weight for context similarity\n\n# Calculate context similarity based on 'Dress code'\ndef calculate_context_similarity(item_context, other_context):\n    return 1.0 if item_context == other_context else 0.0\n\n# Select item with combined similarity bias (context + embedding similarity), using global weights\ndef select_with_combined_bias(df, reference_embedding, reference_context, category):\n    category_df = df[df['Master Category'] == category]\n    if category_df.empty:\n        return pd.DataFrame()  # Return empty if no items in category\n\n    category_embeddings = np.vstack(category_df['embedding'].values)\n    embedding_similarities = cosine_similarity([reference_embedding], category_embeddings)[0]\n    context_similarities = category_df['Outfit Context'].apply(lambda x: calculate_context_similarity(reference_context, x)).values\n\n    # Combine similarities using global weights\n    combined_similarities = (embedding_weight * embedding_similarities) + (context_weight * context_similarities)\n\n    # Normalize combined similarities for valid probability distribution\n    probabilities = combined_similarities / combined_similarities.sum()\n    if np.isnan(probabilities).any() or probabilities.sum() == 0:\n        probabilities = np.ones_like(probabilities) / len(probabilities)\n\n    selected_item = category_df.sample(1, weights=probabilities)\n    return selected_item\n\n# Select random outfit ensuring a top is selected, using global weights\ndef select_random_outfit(df):\n    tops_df = df[df['Master Category'] == 'tops']\n    if tops_df.empty:\n        print(\"No tops available.\")\n        return pd.DataFrame()\n\n    top_item = tops_df.sample(1)\n    reference_embedding = top_item['embedding'].values[0]\n    reference_context = top_item['Outfit Context'].values[0]\n\n    remaining_items_df = df[df['Master Category'] != 'tops']\n    other_items = remaining_items_df['Master Category'].unique()\n    selected_items = [top_item]\n\n    for category in other_items:\n        selected_item = select_with_combined_bias(remaining_items_df, reference_embedding, reference_context, category)\n        if not selected_item.empty:\n            selected_items.append(selected_item)\n\n    selected_items_df = pd.concat(selected_items, ignore_index=True)\n    return selected_items_df\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate similarity score of an outfit, considering global weights\ndef calculate_outfit_similarity(outfit):\n    top_item = outfit[outfit['Master Category'] == 'tops']\n    if top_item.empty:\n        return 0\n\n    top_embedding = top_item['embedding'].values[0]\n    top_context = top_item['Outfit Context'].values[0]\n    total_score = 0\n\n    for index, item in outfit.iterrows():\n        if item['Master Category'] != 'tops':\n            embedding_similarity = cosine_similarity([top_embedding], [item['embedding']])[0][0]\n            context_similarity = calculate_context_similarity(top_context, item['Outfit Context'])\n            combined_similarity = (embedding_weight * embedding_similarity) + (context_weight * context_similarity)\n            total_score += combined_similarity\n\n    return total_score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate, rank, and select the top outfits using global weights\ndef generate_and_rank_outfits(df, num_outfits=10):\n    generated_outfits = []\n\n    for i in range(num_outfits):\n        print(f\"Generating outfit {i+1}/{num_outfits}\")\n        outfit = select_random_outfit(df)\n        \n        if not outfit.empty:\n            similarity_score = calculate_outfit_similarity(outfit)\n            generated_outfits.append({\n                'outfit': outfit,\n                'similarity_score': similarity_score\n            })\n    \n    ranked_outfits = sorted(generated_outfits, key=lambda x: x['similarity_score'], reverse=True)\n    return ranked_outfits[:3]  # Return the top 3 outfits\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display and print images for each outfit in top 3\ndef display_outfit_images(outfits):\n    for idx, outfit_info in enumerate(outfits, 1):\n        print(f\"Displaying images for Rank {idx} - Similarity Score: {outfit_info['similarity_score']}\")\n\n        outfit = outfit_info['outfit']\n        categories_order = ['tops', 'bottoms', 'footwear', 'accessories']\n        images = []\n\n        for category in categories_order:\n            item = outfit[outfit['Master Category'] == category]\n            if not item.empty:\n                image_path = item['Image File Path'].values[0]\n                try:\n                    img = Image.open(image_path)\n                    img = ImageOps.fit(img, (200, 200))  # Resize for uniform display\n                    images.append(img)\n                except Exception as e:\n                    print(f\"Could not open image {image_path}: {e}\")\n\n        if images:\n            combined_image = Image.new('RGB', (200 * len(images), 200))\n            for i, img in enumerate(images):\n                combined_image.paste(img, (i * 200, 0))\n            \n            plt.figure(figsize=(10, 5))\n            plt.imshow(combined_image)\n            plt.axis('off')\n            plt.title(f\"Outfit for Rank {idx}\")\n            plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = 1\nwhile m <= 100:\n    print(\"Iteration \",m)\n    # Generate and rank outfits with global weights\n    top_outfits = generate_and_rank_outfits(df, num_outfits=10)\n\n    # Display images of top 3 outfits\n    display_outfit_images(top_outfits)\n\n    # Randomly select one final outfit from the top 3\n    final_outfit = random.choice(top_outfits)['outfit']\n    print(\"Final selected outfit:\")\n    print(final_outfit[['Master Category', 'Outfit Piece', 'Pattern', 'Color', 'Material', 'Season', 'Weather', 'Dress code']])\n    \n    m += 1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}