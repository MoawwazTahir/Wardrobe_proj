{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":329006,"sourceType":"datasetVersion","datasetId":139630},{"sourceId":9701193,"sourceType":"datasetVersion","datasetId":5932428},{"sourceId":9701704,"sourceType":"datasetVersion","datasetId":5932825},{"sourceId":9701741,"sourceType":"datasetVersion","datasetId":5932852}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence_transformers einops\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:59:29.946400Z","iopub.execute_input":"2024-10-24T13:59:29.946834Z","iopub.status.idle":"2024-10-24T13:59:44.017222Z","shell.execute_reply.started":"2024-10-24T13:59:29.946792Z","shell.execute_reply":"2024-10-24T13:59:44.015885Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0+cpu)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops, sentence_transformers\nSuccessfully installed einops-0.8.0 sentence_transformers-3.2.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport random\nimport numpy as np\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\n\n# Load CSV file\ndf = pd.read_csv(\"/kaggle/input/demo-csv-2/Demo_captions_2.csv\")\n\n# Define the base directory for the images\nimage_dir = \"/kaggle/input/demo-pics-2/Demo closet\"\n\n# Update the image file paths\ndf['Image File Path'] = df['Image File Name'].apply(lambda x: os.path.join(image_dir, x))\n\n# Load the new model: nomic-ai/nomic-embed-text-v1\nmodel_name = \"nomic-ai/nomic-embed-text-v1\"\nmodel = SentenceTransformer(model_name, trust_remote_code=True, device='cpu')\n\n# Function to generate embedding for a text\ndef generate_embedding(text):\n    embedding = model.encode([text])[0]  # Generate embedding\n    return embedding\n\n# Combine relevant columns to form item description for embeddings\ndf['description'] = df[['Outfit Piece', 'Pattern', 'Color', 'Material', 'Season', 'Weather', 'Dress code']].apply(\n    lambda row: ' '.join(row.values.astype(str)), axis=1\n)\n\n# Generate embeddings for each clothing item\ndf['embedding'] = df['description'].apply(lambda x: generate_embedding(x))\n\n# Convert the embeddings to a matrix for similarity calculations\nembedding_matrix = np.vstack(df['embedding'].values)\n\n# Calculate cosine similarity matrix\nsimilarity_matrix = cosine_similarity(embedding_matrix)\n\n# Use 'Dress code' as the context for matching similar styles\ndf['Outfit Context'] = df['Dress code']\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T13:59:44.020150Z","iopub.execute_input":"2024-10-24T13:59:44.020688Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11553bc210a340a8862adcff12f0c95f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/128 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69578088443b47ca9d3b84ed9e4685dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/70.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4c7212bd62842f7bcae94b9e6aa7d4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edb92b1d1cbe4d3ebe85bc05450b447d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1b228c6d70b476a9699b40653a9541b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_hf_nomic_bert.py:   0%|          | 0.00/1.96k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d374a57cbe2b4c399d99b8f792a6548b"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n- configuration_hf_nomic_bert.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_hf_nomic_bert.py:   0%|          | 0.00/85.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdb9c6969cbf4c3e9ea7ac6713f0b0fc"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n- modeling_hf_nomic_bert.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/547M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19247cb8aa7c430e80610a75d80b774a"}},"metadata":{}}]},{"cell_type":"code","source":"# Function to calculate context similarity based on 'Dress code'\ndef calculate_context_similarity(item_context, other_context):\n    return 1.0 if item_context == other_context else 0.0  # Full similarity if contexts match, otherwise 0\n\n# Function to select an item using combined similarity bias (context + embedding similarity)\ndef select_with_combined_bias(df, reference_embedding, reference_context, category):\n    # Filter the items by category\n    category_df = df[df['Master Category'] == category]\n    \n    if category_df.empty:\n        return pd.DataFrame()  # Return empty if no items in category\n\n    # Calculate cosine similarity between reference item and items in this category\n    category_embeddings = np.vstack(category_df['embedding'].values)\n    embedding_similarities = cosine_similarity([reference_embedding], category_embeddings)[0]\n\n    # Calculate context similarity between reference item and items in this category\n    context_similarities = category_df['Outfit Context'].apply(lambda x: calculate_context_similarity(reference_context, x)).values\n\n    # Combine both similarities with a weighting factor\n    embedding_weight = 0.3\n    context_weight = 3\n    combined_similarities = (embedding_weight * embedding_similarities) + (context_weight * context_similarities)\n\n    # Normalize combined similarities for valid probability distribution\n    probabilities = combined_similarities / combined_similarities.sum()\n\n    # Sample an item based on the combined similarity weights\n    selected_item = category_df.sample(1, weights=probabilities)\n\n    return selected_item\n\n# Function to select a random outfit ensuring a top is selected\ndef select_random_outfit(df):\n    # Ensure at least one 'top' is selected\n    tops_df = df[df['Master Category'] == 'tops']\n\n    if tops_df.empty:\n        print(\"No tops available.\")\n        return pd.DataFrame()\n\n    # Select one top item\n    top_item = tops_df.sample(1)\n\n    # Reference embedding and context for similarity calculations\n    reference_embedding = top_item['embedding'].values[0]\n    reference_context = top_item['Outfit Context'].values[0]\n\n    # Select other items based on similarity to the top (both embedding and context)\n    remaining_items_df = df[df['Master Category'] != 'tops']\n    other_items = remaining_items_df['Master Category'].unique()\n\n    selected_items = [top_item]\n\n    # Select one item per category, with bias towards similarity to the top item\n    for category in other_items:\n        selected_item = select_with_combined_bias(remaining_items_df, reference_embedding, reference_context, category)\n        if not selected_item.empty:\n            selected_items.append(selected_item)\n\n    # Concatenate all selected items into a single DataFrame\n    selected_items_df = pd.concat(selected_items, ignore_index=True)\n\n    return selected_items_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to generate and save 100 outfits\ndef generate_and_save_outfits(df, iterations=100, save_file=\"/kaggle/working/generated_outfits.csv\"):\n    results = []\n\n    for i in range(iterations):\n        print(f\"Generating outfit {i+1}/{iterations}\")\n        selected_outfit_items = select_random_outfit(df)\n        \n        if not selected_outfit_items.empty:\n            for index, item in selected_outfit_items.iterrows():\n                results.append({\n                    'Iteration': i+1,\n                    'Master Category': item['Master Category'],\n                    'Outfit Piece': item['Outfit Piece'],\n                    'Pattern': item['Pattern'],\n                    'Color': item['Color'],\n                    'Material': item['Material'],\n                    'Season': item['Season'],\n                    'Weather': item['Weather'],\n                    'Dress Code': item['Dress code'],\n                    'Image File Path': item['Image File Path'],\n                    'Description': item['description']\n                })\n    \n    # Convert results to DataFrame and save as CSV\n    results_df = pd.DataFrame(results)\n    results_df.to_csv(save_file, index=False)\n    print(f\"{iterations} outfits have been generated and saved to '{save_file}'.\")\n\n# Function to load CSV and create combined outfit images, save them in a folder, and print them\ndef create_combined_outfit_image(csv_file, save_folder=\"/kaggle/working/outfit_images\"):\n    # Create a directory to store the combined outfit images if it doesn't exist\n    if not os.path.exists(save_folder):\n        os.makedirs(save_folder)\n    \n    # Load the CSV file\n    outfits_df = pd.read_csv(csv_file)\n    \n    # Group the outfits by 'Iteration' to combine top, bottom, footwear, and accessory\n    grouped_outfits = outfits_df.groupby('Iteration')\n    \n    for iteration, group in grouped_outfits:\n        # Initialize a list to hold images in the order: top, bottom, footwear, accessory\n        images = []\n\n        # Ensure the items are ordered in the expected way\n        categories_order = ['tops', 'bottoms', 'footwear', 'accessories']\n\n        for category in categories_order:\n            item = group[group['Master Category'] == category]\n            if not item.empty:\n                image_path = item['Image File Path'].values[0]\n                try:\n                    img = Image.open(image_path)\n                    img = ImageOps.fit(img, (200, 200))  # Resize each item to a fixed size (200x200 for example)\n                    images.append(img)\n                except Exception as e:\n                    print(f\"Could not open image {image_path}: {e}\")\n        \n        # If all categories have been found, combine the images\n        if len(images) == len(categories_order):\n            combined_image = Image.new('RGB', (200 * len(images), 200))  # Combine images horizontally\n            for i, img in enumerate(images):\n                combined_image.paste(img, (i * 200, 0))\n            \n            # Save the combined image for this iteration in the specified folder\n            combined_image_path = os.path.join(save_folder, f\"outfit_combined_{iteration}.png\")\n            combined_image.save(combined_image_path)\n            \n            # Display the image inline using matplotlib\n            plt.figure(figsize=(10, 5))\n            plt.imshow(combined_image)\n            plt.axis('off')  # Hide axes\n            plt.title(f\"Outfit for iteration {iteration}\")\n            plt.show()  # Display the image\n            \n            print(f\"Outfit for iteration {iteration} saved as '{combined_image_path}'\")\n        else:\n            print(f\"Skipping iteration {iteration}: Missing categories.\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the generation for 100 iterations and save the outfits to CSV\ngenerate_and_save_outfits(df, iterations=100)\n\n# Generate and display combined outfit images\ncreate_combined_outfit_image(\"/kaggle/working/generated_outfits.csv\", save_folder=\"/kaggle/working/outfit_images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}