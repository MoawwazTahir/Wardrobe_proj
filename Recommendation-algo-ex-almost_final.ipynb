{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":329006,"sourceType":"datasetVersion","datasetId":139630},{"sourceId":9701193,"sourceType":"datasetVersion","datasetId":5932428},{"sourceId":9701704,"sourceType":"datasetVersion","datasetId":5932825},{"sourceId":9701741,"sourceType":"datasetVersion","datasetId":5932852}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence_transformers einops","metadata":{"execution":{"iopub.status.busy":"2024-11-08T06:24:33.516679Z","iopub.execute_input":"2024-11-08T06:24:33.517806Z","iopub.status.idle":"2024-11-08T06:24:34.631240Z","shell.execute_reply.started":"2024-11-08T06:24:33.517749Z","shell.execute_reply":"2024-11-08T06:24:34.628079Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport random\nimport numpy as np\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\n# Load CSV file\ndf = pd.read_csv(\"/kaggle/input/demo-csv-2/Demo_captions_2.csv\")\n\n# Define the base directory for the images\nimage_dir = \"/kaggle/input/demo-pics-2/Demo closet\"\n\n# Update the image file paths\ndf['Image File Path'] = df['Image File Name'].apply(lambda x: os.path.join(image_dir, x))\n\n# Load the model\nmodel_name = \"nomic-ai/nomic-embed-text-v1\"\nmodel = SentenceTransformer(model_name, trust_remote_code=True, device='cpu')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-08T06:24:34.632890Z","iopub.status.idle":"2024-11-08T06:24:34.633410Z","shell.execute_reply.started":"2024-11-08T06:24:34.633157Z","shell.execute_reply":"2024-11-08T06:24:34.633183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to generate embedding for a text\ndef generate_embedding(text):\n    embedding = model.encode([text])[0]  # Generate embedding\n    return embedding\n\n# Combine relevant columns to form item description for embeddings\ndf['description'] = df[['Outfit Piece', 'Pattern', 'Color', 'Material', 'Season', 'Weather', 'Dress code']].apply(\n    lambda row: ' '.join(row.values.astype(str)), axis=1\n)\n\n# Generate embeddings for each clothing item\ndf['embedding'] = df['description'].apply(lambda x: generate_embedding(x))\n\n# Set Outfit Context based on 'Dress code'\ndf['Outfit Context'] = df['Dress code']\n","metadata":{"execution":{"iopub.status.busy":"2024-11-08T06:24:34.636136Z","iopub.status.idle":"2024-11-08T06:24:34.636852Z","shell.execute_reply.started":"2024-11-08T06:24:34.636497Z","shell.execute_reply":"2024-11-08T06:24:34.636533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Global variables for adjustable weights\nembedding_weight = 0.8  # Adjustable weight for embedding similarity\ncontext_weight = 10   # Adjustable weight for context similarity\n# Calculate context similarity based on 'Dress code'\ndef calculate_context_similarity(item_context, other_context):\n    \"\"\"\n    Apply a penalty if the contexts mismatch\n    \"\"\"\n    penalty_factor = 0.7  # Deduct this factor for mismatched contexts\n    return penalty_factor if item_context != other_context else 1.0\n\ndef check_for_inappropriate_pairing(top, bottom):\n    # Ensure we access the values directly\n    top_context = top['Outfit Context'] if isinstance(top, pd.Series) else top['Outfit Context'].iloc[0]\n    bottom_context = bottom['Outfit Context'] if isinstance(bottom, pd.Series) else bottom['Outfit Context'].iloc[0]\n    \n    # Check for inappropriate pairing\n    if top_context == 'formal' and bottom_context == 'casual':\n        return -2  # Penalty for incompatible pairing\n    return 0  # No penalty for compatible pair\n\n# Random penalty for variety\ndef apply_random_penalty():\n    if random.random() < 0.1:  # 10% chance of applying penalty\n        return -0.5  # Random penalty\n    return 0  # No penalty","metadata":{"execution":{"iopub.status.busy":"2024-11-08T06:24:34.638853Z","iopub.status.idle":"2024-11-08T06:24:34.639482Z","shell.execute_reply.started":"2024-11-08T06:24:34.639158Z","shell.execute_reply":"2024-11-08T06:24:34.639190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select item with combined similarity bias (context + embedding similarity)\ndef select_with_combined_bias(df, reference_embedding, reference_context, category):\n    category_df = df[df['Master Category'] == category]\n    if category_df.empty:\n        return pd.DataFrame()  # Return empty if no items in category\n    \n    category_embeddings = np.vstack(category_df['embedding'].values)\n    embedding_similarities = cosine_similarity([reference_embedding], category_embeddings)[0]\n    context_similarities = category_df['Outfit Context'].apply(lambda x: calculate_context_similarity(reference_context, x)).values\n    \n    # Combine similarities using global weights\n    combined_similarities = (embedding_weight * embedding_similarities) + (context_weight * context_similarities)\n    \n    # Normalize combined similarities for valid probability distribution\n    probabilities = combined_similarities / combined_similarities.sum()\n    if np.isnan(probabilities).any() or probabilities.sum() == 0:\n        probabilities = np.ones_like(probabilities) / len(probabilities)\n    \n    selected_item = category_df.sample(1, weights=probabilities)\n    return selected_item\n\n# Select random outfit ensuring a top is selected\ndef select_random_outfit(df):\n    tops_df = df[df['Master Category'] == 'tops']\n    if tops_df.empty:\n        print(\"No tops available.\")\n        return pd.DataFrame()\n\n    top_item = tops_df.sample(1)\n    reference_embedding = top_item['embedding'].values[0]\n    reference_context = top_item['Outfit Context'].values[0]\n\n    remaining_items_df = df[df['Master Category'] != 'tops']\n    other_items = remaining_items_df['Master Category'].unique()\n    selected_items = [top_item]\n\n    for category in other_items:\n        selected_item = select_with_combined_bias(remaining_items_df, reference_embedding, reference_context, category)\n        if not selected_item.empty:\n            selected_items.append(selected_item)\n\n    selected_items_df = pd.concat(selected_items, ignore_index=True)\n    return selected_items_df\n\n# Calculate similarity score of an outfit, considering global weights\ndef calculate_outfit_similarity(outfit):\n    top_item = outfit[outfit['Master Category'] == 'tops']\n    if top_item.empty:\n        return 0\n    \n    top_embedding = top_item['embedding'].values[0]\n    top_context = top_item['Outfit Context'].values[0]\n    total_score = 0\n    \n    for index, item in outfit.iterrows():\n        if item['Master Category'] != 'tops':\n            embedding_similarity = cosine_similarity([top_embedding], [item['embedding']])[0][0]\n            context_similarity = calculate_context_similarity(top_context, item['Outfit Context'])\n            combined_similarity = (embedding_weight * embedding_similarity) + (context_weight * context_similarity)\n            total_score += combined_similarity\n            \n            # Apply penalties\n            total_score += check_for_inappropriate_pairing(top_item, item)\n            total_score += apply_random_penalty()\n    \n    return total_score\n\n# Generate, rank, and select the top outfits with a minimum similarity threshold\ndef generate_and_rank_outfits(df, num_outfits=10, min_similarity_score=27):\n    generated_outfits = []\n\n    # Continue generating outfits until we have at least 3 that meet the minimum score\n    while len([outfit for outfit in generated_outfits if outfit['similarity_score'] >= min_similarity_score]) < 3:\n        batch_outfits = []\n        \n        # Generate a batch of outfits\n        for i in range(num_outfits):\n            print(f\"Generating outfit {i+1}/{num_outfits}\")\n            outfit = select_random_outfit(df)\n            \n            if not outfit.empty:\n                similarity_score = calculate_outfit_similarity(outfit)\n                \n                # Only add outfits that meet the minimum similarity score threshold\n                if similarity_score >= min_similarity_score:\n                    batch_outfits.append({\n                        'outfit': outfit,\n                        'similarity_score': similarity_score\n                    })\n\n        # Add qualified outfits from this batch to the main list\n        generated_outfits.extend(batch_outfits)\n\n    # Filter to only those meeting the minimum similarity score\n    qualified_outfits = [outfit for outfit in generated_outfits if outfit['similarity_score'] >= min_similarity_score]\n\n    # Sort outfits by similarity score in descending order and return the top 3\n    ranked_outfits = sorted(qualified_outfits, key=lambda x: x['similarity_score'], reverse=True)\n    return ranked_outfits[:3]  # Ensure only the top 3 outfits are returned\n\n# Display and print images for each outfit in top 3\ndef display_outfit_images(outfits):\n    for idx, outfit_info in enumerate(outfits, 1):\n        print(f\"Displaying images for Rank {idx} - Similarity Score: {outfit_info['similarity_score']}\")\n        \n        outfit = outfit_info['outfit']\n        categories_order = ['tops', 'bottoms', 'footwear', 'accessories']\n        images = []\n\n        for category in categories_order:\n            item = outfit[outfit['Master Category'] == category]\n            if not item.empty:\n                image_path = item['Image File Path'].values[0]\n                try:\n                    img = Image.open(image_path)\n                    img = ImageOps.fit(img, (200, 200))  # Resize for uniform display\n                    images.append(img)\n                except Exception as e:\n                    print(f\"Could not open image {image_path}: {e}\")\n\n        if images:\n            combined_image = Image.new('RGB', (200 * len(images), 200))\n            for i, img in enumerate(images):\n                combined_image.paste(img, (i * 200, 0))\n            \n            plt.figure(figsize=(10, 5))\n            plt.imshow(combined_image)\n            plt.axis('off')\n            plt.title(f\"Outfit for Rank {idx}\")\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-08T06:24:34.642220Z","iopub.status.idle":"2024-11-08T06:24:34.642907Z","shell.execute_reply.started":"2024-11-08T06:24:34.642551Z","shell.execute_reply":"2024-11-08T06:24:34.642586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the generation and selection loop\nfor m in range(1, 101):\n    print(\"Iteration #\", m)\n    \n    # Generate and rank outfits with global weights\n    top_outfits = generate_and_rank_outfits(df, num_outfits=10)\n    \n    # Display images of top 3 outfits\n    display_outfit_images(top_outfits)\n    \n    # Randomly select one final outfit from the top 3\n    final_outfit = random.choice(top_outfits)['outfit']\n    print(\"Final selected outfit:\")\n    print(final_outfit[['Master Category', 'Outfit Piece', 'Pattern', 'Color', 'Material', 'Season', 'Weather', 'Dress code']])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-08T06:24:34.645607Z","iopub.status.idle":"2024-11-08T06:24:34.647426Z","shell.execute_reply.started":"2024-11-08T06:24:34.646081Z","shell.execute_reply":"2024-11-08T06:24:34.646124Z"},"trusted":true},"execution_count":null,"outputs":[]}]}